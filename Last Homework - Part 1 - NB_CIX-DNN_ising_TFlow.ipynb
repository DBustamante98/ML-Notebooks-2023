{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 12: Identifying Phases in the 2D Ising Model with TensorFlow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import numpy as np\n",
    "import sys, os, argparse\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import dtypes\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "seed=12\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load and Process the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading data\n"
     ]
    }
   ],
   "source": [
    "import pickle, os\n",
    "from urllib.request import urlopen \n",
    "\n",
    "def load_data():\n",
    "    url_main = 'https://physics.bu.edu/~pankajm/ML-Review-Datasets/isingMC/';\n",
    "    data_file_name = \"Ising2DFM_reSample_L40_T=All.pkl\" \n",
    "    label_file_name = \"Ising2DFM_reSample_L40_T=All_labels.pkl\"\n",
    "\n",
    "    data = pickle.load(urlopen(url_main + data_file_name)) # pickle reads the file and returns the Python object (1D array, compressed bits)\n",
    "    data = np.unpackbits(data).reshape(-1, 1600) # Decompress array and reshape for convenience\n",
    "    data=data.astype('int')\n",
    "    data[np.where(data==0)]=-1 # map 0 state to -1 (Ising variable can take values +/-1)\n",
    "\n",
    "    labels = pickle.load(urlopen(url_main + label_file_name)) # pickle reads the file and returns the Python object (here just a 1D array with the binary labels)\n",
    "    \n",
    "    print(\"Finished loading data\")\n",
    "    return data, labels\n",
    "\n",
    "def prepare_data(data, labels, dtype=dtypes.float32, test_size=0.2, validation_size=5000):\n",
    "    \n",
    "    L=40 # linear system size\n",
    "\n",
    "    X_ordered=data[:70000,:].reshape(-1,40,40,1)\n",
    "    Y_ordered=labels[:70000]\n",
    "\n",
    "    X_critical=data[70000:100000,:].reshape(-1,40,40,1)\n",
    "    Y_critical=labels[70000:100000]\n",
    "\n",
    "    X_disordered=data[100000:,:].reshape(-1,40,40,1)\n",
    "    Y_disordered=labels[100000:]\n",
    "\n",
    "    X=np.concatenate((X_ordered,X_disordered)) #np.concatenate((X_ordered,X_critical,X_disordered))\n",
    "    Y=np.concatenate((Y_ordered,Y_disordered)) #np.concatenate((Y_ordered,Y_critical,Y_disordered))\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, train_size=1.0-test_size)\n",
    "\n",
    "    Y_train=to_categorical(Y_train)\n",
    "    Y_test=to_categorical(Y_test)\n",
    "    Y_critical=to_categorical(Y_critical)\n",
    "\n",
    "    if not 0 <= validation_size <= len(X_train):\n",
    "        raise ValueError('Validation size should be between 0 and {}. Received: {}.'.format(len(X_train), validation_size))\n",
    "\n",
    "    X_validation = X_train[:validation_size]\n",
    "    Y_validation = Y_train[:validation_size]\n",
    "    X_train = X_train[validation_size:]\n",
    "    Y_train = Y_train[validation_size:]\n",
    "\n",
    "    dataset = {\n",
    "        'train': (X_train, Y_train),\n",
    "        'test': (X_test, Y_test),\n",
    "        'critical': (X_critical, Y_critical),\n",
    "        'validation': (X_validation, Y_validation)\n",
    "    }\n",
    "    return dataset\n",
    "\n",
    "def prepare_Ising_DNN():\n",
    "    data, labels = load_data()\n",
    "    return prepare_data(data, labels, test_size=0.2, validation_size=5000)\n",
    "\n",
    "IsingCNN = prepare_Ising_DNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Convolutional Neural Nets with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_CNN():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(10, kernel_size=(5, 5),\n",
    "                     activation='relu',\n",
    "                     input_shape=(40,40,1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(20, (5, 5), activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1000, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer='Adam',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "774/774 [==============================] - 55s 70ms/step - loss: 0.0048 - accuracy: 0.9981 - val_loss: 2.4930e-06 - val_accuracy: 1.0000\n",
      "Epoch 2/2\n",
      "774/774 [==============================] - 58s 75ms/step - loss: 1.3873e-07 - accuracy: 1.0000 - val_loss: 8.4023e-07 - val_accuracy: 1.0000\n",
      "813/813 [==============================] - 6s 8ms/step - loss: 2.8447e-07 - accuracy: 1.0000\n",
      "938/938 [==============================] - 7s 8ms/step - loss: 0.2074 - accuracy: 0.9451\n",
      "\n",
      "Test loss: 2.8447396971387207e-07\n",
      "Test accuracy: 1.0\n",
      "Critical data loss: 0.20744609832763672\n",
      "Critical data accuracy: 0.9451333284378052\n"
     ]
    }
   ],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"./logs\")\n",
    "\n",
    "# training parameters\n",
    "batch_size = 128\n",
    "epochs = 2\n",
    "\n",
    "# create the deep conv net\n",
    "model_CNN=create_CNN()\n",
    "\n",
    "# train CNN\n",
    "model_CNN.fit(*IsingCNN[\"train\"],\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=IsingCNN[\"validation\"],\n",
    "          callbacks=[tensorboard_callback])\n",
    "\n",
    "# evaliate model\n",
    "score = model_CNN.evaluate(*IsingCNN[\"test\"], verbose=1)\n",
    "score_critical = model_CNN.evaluate(*IsingCNN[\"critical\"], verbose=1)\n",
    "\n",
    "print('\\nTest loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print('Critical data loss:', score_critical[0])\n",
    "print('Critical data accuracy:', score_critical[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-76b35febfd6f07c7\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-76b35febfd6f07c7\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=\"./logs\" --host localhost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
